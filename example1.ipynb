{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Title: Sentiment Analysis Example 1\n",
      "# Author: Dax Gerts\n",
      "# Date: 2 February 2016\n",
      "# Description: introductory example to sentiment analysis with python-nltk, based heavily on example provided by at www.nltk.org/howto/sentiment.html\n",
      "#   Example uses the 'sentiment anlyzer' tool to prepare data for classification with Naive Bayes Classifier\n",
      "\n",
      "## Modules\n",
      "\n",
      "# 1. NaiveBayesClassifier (machine learning method)\n",
      "\n",
      "# Naive Bayes Classifier is the machine learning model used in this example\n",
      "# More info https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n",
      "\n",
      "from nltk.classify import NaiveBayesClassifier\n",
      "\n",
      "# 2. Subjectivity (the data)\n",
      "\n",
      "# Corpus of phrases divided between subjective/objective\n",
      "\n",
      "# \"The Subjectivity Dataset contains 5000 subjective and 5000 objective processed sentences.\"\n",
      "# More info www.nltk.org/howto/corpus.html\n",
      "\n",
      "from nltk.corpus import subjectivity\n",
      "\n",
      "# 3. NLTK Sentiment Tools\n",
      "\n",
      "# The NLTK's collection of sentiment analysis tools\n",
      "# More info www.nltk.org\n",
      "\n",
      "from nltk.sentiment import SentimentAnalyzer\n",
      "from nltk.sentiment.util import *\n",
      "\n",
      "## Build training and testing data sets\n",
      "\n",
      "# Size of dataset(s)\n",
      "\n",
      "n = 1000\n",
      "\n",
      "# Get \"n\" subjective and objective phrases from subjectivity corpus\n",
      "\n",
      "subjective = [(sentences,'subj') for sentences in subjectivity.sents(categories='subj')[:n]]\n",
      "objective = [(sentences,'obj') for sentences in subjectivity.sents(categories='obj')[:n]]\n",
      "\n",
      "# Here's what the first item in \"subjective\" looks like\n",
      "# Note that it's stores as (phrase, label)\n",
      "\n",
      "subjective[0]\n",
      "\n",
      "# Create separate training and test data sets, this is pretty standard in any data mining/machine learning task\n",
      "# The typical split is, as seen here (training = 80%, train = 20%)\n",
      "\n",
      "training_subjective = subjective[:int(.8*n)]\n",
      "test_subjective = subjective[int(.8*n):n]\n",
      "training_objective = objective[:int(.8*n)]\n",
      "test_objective = objective[int(.8*n):n]\n",
      "\n",
      "# Now aggregate the training and test sets\n",
      "\n",
      "training = training_subjective + training_objective\n",
      "test = test_subjective + test_objective\n",
      "\n",
      "## Apply sentiment analysis to data to extract new \"features\"\n",
      "\n",
      "# Initialize sentiment analyzer object\n",
      "\n",
      "sentiment_analyzer = SentimentAnalyzer()\n",
      "\n",
      "# Mark all negative words in training data, using existing list of negative words\n",
      "\n",
      "all_negative_words = sentiment_analyzer.all_words([mark_negation(data) for data in training])\n",
      "\n",
      "unigram_features = sentiment_analyzer.unigram_word_feats(all_negative_words, min_freq=4)\n",
      "len(unigram_features)\n",
      "sentiment_analyzer.add_feat_extractor(extract_unigram_feats,unigrams=unigram_features)\n",
      "\n",
      "training_final = sentiment_analyzer.apply_features(training)\n",
      "test_final = sentiment_analyzer.apply_features(test)\n",
      "\n",
      "## Traing model and test\n",
      "\n",
      "model = NaiveBayesClassifier.train\n",
      "classifer = sentiment_analyzer.train(model, training_final)\n",
      "\n",
      "for key, value in sorted(sentiment_analyzer.evaluate(test_final).items()):\n",
      "    print('{0}: {1}'.format(key,value))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "cannot import name subjectivity",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-b05574e75d34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# More info www.nltk.org/howto/corpus.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubjectivity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# 3. NLTK Sentiment Tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: cannot import name subjectivity"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}